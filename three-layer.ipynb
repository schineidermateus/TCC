{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From f:\\TCC\\Projeto\\lib\\base_model.py:8: The name tf.disable_v2_behavior is deprecated. Please use tf.compat.v1.disable_v2_behavior instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\schin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "import pickle\n",
    "import numpy as np                                       # fast vectors and matrices\n",
    "import matplotlib.pyplot as plt                          # plotting\n",
    "from scipy.fftpack import fft\n",
    "\n",
    "from time import time\n",
    "\n",
    "sys.path.insert(0,'lib/')\n",
    "import config\n",
    "import diagnostics\n",
    "import base_model\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import tensorflow as tfw\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "with open(config.labels_path, 'rb') as f:\n",
    "    labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# windowed, exponentially distributed filters between 50Hz and 22kHz\n",
    "def create_filters(d,k):\n",
    "    x = np.linspace(0, 2*np.pi, d, endpoint=False)\n",
    "    wsin = np.empty((1,d,1,k), dtype=np.float32)\n",
    "    wcos = np.empty((1,d,1,k), dtype=np.float32)\n",
    "    start_freq = 50.\n",
    "    end_freq = 6000.\n",
    "    num_cycles = start_freq*d/44000.\n",
    "    scaling_ind = np.log(end_freq/start_freq)/k\n",
    "    window_mask = 1.0-1.0*np.cos(x)\n",
    "    for ind in range(k):\n",
    "        wsin[0,:,0,ind] = window_mask*np.sin(np.exp(ind*scaling_ind)*num_cycles*x)\n",
    "        wcos[0,:,0,ind] = window_mask*np.cos(np.exp(ind*scaling_ind)*num_cycles*x)\n",
    "            \n",
    "    return wsin,wcos\n",
    "\n",
    "class Spectrograms(base_model.Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Spectrograms, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def define_graph(self):\n",
    "        super(Spectrograms, self).define_graph()\n",
    "        \n",
    "        # lvl1 convolutions are shared between regions\n",
    "        self.k = 512              # lvl1 nodes\n",
    "        self.d = 4096              # lvl1 receptive field\n",
    "        \n",
    "        self.k2 = 512              # lvl2 nodes\n",
    "\n",
    "        # number of lvl1 features\n",
    "        regions = 1 + (self.window - self.d)/self.stride\n",
    "        print ('Number of V1 feature regions: {}'.format(regions))\n",
    "\n",
    "        wsin,wcos = create_filters(self.d,self.k)\n",
    "        \n",
    "        wscale = tf.constant(10e-5, dtype=tf.float32)\n",
    "\n",
    "        with tf.variable_scope('parameters'):\n",
    "            w1 = tf.Variable(wscale * tf.random_normal([tf.cast(regions, tf.int32) * tf.cast(self.k, tf.int32), self.k2], seed=999))\n",
    "            w1avg = self.register_weights(w1,'w1',average=.9998)\n",
    "            beta = tf.Variable(wscale*tf.random_normal([self.k2,self.m],seed=999))\n",
    "            betaavg = self.register_weights(beta,'beta',average=.9998)\n",
    "\n",
    "        with tf.variable_scope('queued_model'):\n",
    "            zx = tf.square(tf.nn.conv2d(self.xq,wsin,strides=[1,1,self.stride,1],padding='VALID')) \\\n",
    "               + tf.square(tf.nn.conv2d(self.xq,wcos,strides=[1,1,self.stride,1],padding='VALID'))\n",
    "            z2 = tf.nn.relu(tf.matmul(tf.reshape(tf.log(zx + 10e-12),[self.batch_size,tf.cast(regions, tf.int32)*tf.cast(self.k, tf.int32)]),w1))\n",
    "            y = tf.matmul(z2,beta)\n",
    "            self.loss = tf.reduce_mean(tf.nn.l2_loss(y-tf.reshape(self.yq,[self.batch_size,self.m])))\n",
    "\n",
    "        with tf.variable_scope('direct_model'):\n",
    "            zx = tf.square(tf.nn.conv2d(self.xd,wsin,strides=[1,1,self.stride,1],padding='VALID')) \\\n",
    "               + tf.square(tf.nn.conv2d(self.xd,wcos,strides=[1,1,self.stride,1],padding='VALID'))\n",
    "            z2 = tf.nn.relu(tf.matmul(tf.reshape(tf.log(zx + 10e-12),[tf.shape(self.xd)[0],tf.cast(regions, tf.int32)*tf.cast(self.k, tf.int32)]),w1avg))\n",
    "            self.y_direct = tf.matmul(z2,betaavg)\n",
    "            self.loss_direct = tf.reduce_mean(tf.nn.l2_loss(self.y_direct-self.yd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of V1 feature regions: 25.0\n",
      "WARNING:tensorflow:From f:\\TCC\\Projeto\\lib\\base_model.py:243: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From f:\\TCC\\Projeto\\lib\\base_model.py:243: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    }
   ],
   "source": [
    "model = Spectrograms(labels,checkpoint_path='weights/convnet_mlp_raw/', outputs=1, window=16384, mmap=False, batch_size=100,\n",
    "                    normalize=True, extended_test_set=True, use_mirex=False, init=False, pitch_transforms=5, jitter=.1,\n",
    "                    restrict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizando treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# lr = .000001/3/3\n",
    "# mom = .95\n",
    "\n",
    "# # stop the model if it is already running\n",
    "# model.stop()\n",
    "\n",
    "# # we have to rebuild the graph every time because input queues can't be reopened\n",
    "# model.define_graph()\n",
    "\n",
    "# learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "# opt_op = tf.train.MomentumOptimizer(learning_rate,mom).minimize(model.loss)\n",
    "# with tf.control_dependencies([opt_op]):\n",
    "#     train_step = tf.group(*model.averages)\n",
    "\n",
    "# # start up the session, kick off the worker threads, restore checkpoint, etc.\n",
    "# model.start()\n",
    "\n",
    "# try:\n",
    "#     ptime = time()\n",
    "#     print (model.status_header())\n",
    "#     while True:\n",
    "#         if model.iter % 10000 == 0:\n",
    "#             model.update_status(ptime,time(),lr)\n",
    "#             model.checkpoint()\n",
    "#             print (model.status())\n",
    "#             ptime = time()\n",
    "\n",
    "#         model.sess.run(train_step, feed_dict={learning_rate: lr})\n",
    "#         model.iter += 1\n",
    "\n",
    "# except KeyboardInterrupt:\n",
    "#     model.checkpoint()\n",
    "#     print ('Graceful Exit')\n",
    "# finally:\n",
    "#     model.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burnin=100\n",
    "fig, ((ax1, ax2),(ax3,ax4),(ax5,ax6)) = plt.subplots(3,2)\n",
    "fig.set_figwidth(12)\n",
    "fig.set_figheight(10)\n",
    "ax1.set_title('average precision')\n",
    "ax1.plot(model.stats['iter'][2][burnin:],model.stats['avp_test'][2][burnin:],color='g')\n",
    "ax1.plot(model.stats['iter'][2][burnin:],model.stats['avp_train'][2][burnin:],color='b')\n",
    "ax2.set_title('square loss')\n",
    "ax2.plot(model.stats['iter'][2][burnin:],model.stats['mse_test'][2][burnin:],color='g')\n",
    "ax2.plot(model.stats['iter'][2][burnin:],model.stats['mse_train'][2][burnin:],color='b')\n",
    "ax3.set_title('weights top')\n",
    "ax3.plot(model.stats['iter'][2][burnin:],model.stats['nbeta'][2][burnin:],color='g')\n",
    "ax4.set_title('learning rate')\n",
    "ax4.plot(model.stats['iter'][2][burnin:],model.stats['lr'][2][burnin:],color='g')\n",
    "ax6.set_title('weights middle')\n",
    "ax6.plot(model.stats['iter'][2][burnin:],model.stats['nw1'][2][burnin:],color='g')\n",
    "\n",
    "print (max(model.stats['avp_test'][2]))\n",
    "print (min(model.stats['mse_test'][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Mirex Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test, Yhat, Y, mse_breakdown, avp_breakdown = model.sample_records(config.test_ids, 7500, fixed_stride=512)\n",
    "avp_test = average_precision_score(Y.flatten(),Yhat.flatten())\n",
    "print (avp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\TCC\\Projeto\\lib\\base_model.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  if self.normalize: x /= np.linalg.norm(x) + config.epsilon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvgP\tP\tR\tAcc\tETot\tESub\tEmiss\tEfa\n",
      "4.29\t2.96\t72.88\t0.03\t24.08\t0.06\t0.21\t23.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\TCC\\Projeto\\lib\\base_model.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  if self.normalize: x /= np.linalg.norm(x) + config.epsilon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvgP\tP\tR\tAcc\tETot\tESub\tEmiss\tEfa\n",
      "4.76\t2.40\t73.60\t0.02\t30.14\t0.07\t0.20\t29.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\TCC\\Projeto\\lib\\base_model.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  if self.normalize: x /= np.linalg.norm(x) + config.epsilon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvgP\tP\tR\tAcc\tETot\tESub\tEmiss\tEfa\n",
      "10.16\t3.48\t65.15\t0.03\t18.31\t0.11\t0.24\t17.96\n",
      "0.029083818829743868 24.17844340226082\n"
     ]
    }
   ],
   "source": [
    "Accavg = Etotavg = 0\n",
    "for i in range(3):\n",
    "    _,_,_,Acc,Etot = diagnostics.mirex_statistics(model,i,threshold=.4)\n",
    "    Accavg += Acc\n",
    "    Etotavg += Etot\n",
    "\n",
    "print (Accavg/3.,Etotavg/3.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Extended test set stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_test, Yhat, Y, mse_breakdown, avp_breakdown = model.sample_records(config.test_ids_ext, 7500, fixed_stride=512)\n",
    "avp_test = average_precision_score(Y.flatten(),Yhat.flatten())\n",
    "print (avp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\TCC\\Projeto\\lib\\base_model.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  if self.normalize: x /= np.linalg.norm(x) + config.epsilon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvgP\tP\tR\tAcc\tETot\tESub\tEmiss\tEfa\n",
      "4.29\t2.96\t72.88\t0.03\t24.08\t0.06\t0.21\t23.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\TCC\\Projeto\\lib\\base_model.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  if self.normalize: x /= np.linalg.norm(x) + config.epsilon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvgP\tP\tR\tAcc\tETot\tESub\tEmiss\tEfa\n",
      "4.76\t2.40\t73.60\t0.02\t30.14\t0.07\t0.20\t29.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\TCC\\Projeto\\lib\\base_model.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  if self.normalize: x /= np.linalg.norm(x) + config.epsilon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvgP\tP\tR\tAcc\tETot\tESub\tEmiss\tEfa\n",
      "10.16\t3.48\t65.15\t0.03\t18.31\t0.11\t0.24\t17.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\TCC\\Projeto\\lib\\base_model.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  if self.normalize: x /= np.linalg.norm(x) + config.epsilon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvgP\tP\tR\tAcc\tETot\tESub\tEmiss\tEfa\n",
      "2.49\t1.30\t75.91\t0.01\t58.05\t0.00\t0.24\t57.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\TCC\\Projeto\\lib\\base_model.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  if self.normalize: x /= np.linalg.norm(x) + config.epsilon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvgP\tP\tR\tAcc\tETot\tESub\tEmiss\tEfa\n",
      "1.16\t1.05\t66.13\t0.01\t62.36\t0.08\t0.26\t62.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\TCC\\Projeto\\lib\\base_model.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  if self.normalize: x /= np.linalg.norm(x) + config.epsilon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvgP\tP\tR\tAcc\tETot\tESub\tEmiss\tEfa\n",
      "4.93\t3.41\t68.72\t0.03\t19.70\t0.07\t0.24\t19.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\TCC\\Projeto\\lib\\base_model.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  if self.normalize: x /= np.linalg.norm(x) + config.epsilon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvgP\tP\tR\tAcc\tETot\tESub\tEmiss\tEfa\n",
      "6.85\t2.07\t61.85\t0.02\t29.48\t0.13\t0.25\t29.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\TCC\\Projeto\\lib\\base_model.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  if self.normalize: x /= np.linalg.norm(x) + config.epsilon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvgP\tP\tR\tAcc\tETot\tESub\tEmiss\tEfa\n",
      "5.82\t3.22\t66.01\t0.03\t20.09\t0.08\t0.26\t19.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\TCC\\Projeto\\lib\\base_model.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  if self.normalize: x /= np.linalg.norm(x) + config.epsilon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvgP\tP\tR\tAcc\tETot\tESub\tEmiss\tEfa\n",
      "6.14\t3.30\t68.55\t0.03\t20.36\t0.06\t0.26\t20.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\TCC\\Projeto\\lib\\base_model.py:168: RuntimeWarning: invalid value encountered in divide\n",
      "  if self.normalize: x /= np.linalg.norm(x) + config.epsilon\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AvgP\tP\tR\tAcc\tETot\tESub\tEmiss\tEfa\n",
      "4.77\t3.27\t67.41\t0.03\t20.21\t0.07\t0.26\t19.88\n",
      "0.026102943541238016 30.279090379198863\n"
     ]
    }
   ],
   "source": [
    "Accavg = Etotavg = 0\n",
    "for i in range(10):\n",
    "    _,_,_,Acc,Etot = diagnostics.mirex_statistics(model,i,threshold=.4)\n",
    "    Accavg += Acc\n",
    "    Etotavg += Etot\n",
    "\n",
    "print (Accavg/10.,Etotavg/10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
